{"cells":[{"cell_type":"markdown","metadata":{"id":"ZIAkIlfmCe1B"},"source":["# Introdu√ß√£o ao aprendizado de m√°quina (*Machine Learning*) em Python üêç"]},{"cell_type":"markdown","metadata":{"id":"fA93WUy1zzWf"},"source":["O conte√∫do deste tutorial √© baseado neste **v√≠deo:** https://www.youtube.com/watch?v=_Z9TRANg4c0&list=PLOU2XLYxmsII9mzQ-Xxug4l2o04JBrkLV&index=1\n"]},{"cell_type":"markdown","metadata":{"id":"FQPelATso5Y0"},"source":["## Bibliotecas"]},{"cell_type":"markdown","metadata":{"id":"DzbtdRcZDO9B"},"source":["Existem diversas bibliotecas para a implementa√ß√£o de modelos de *aprendizado de m√°quina* em Python, dentre estas as bibliotecas `tensorflow` e `numpy`. Tais bibliotecas ser√°o utilizadas neste tutorial."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X9uIpOS2zx7k"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras"]},{"cell_type":"markdown","metadata":{"id":"2Idhlt8M_qUM"},"source":["## Perceptron: a estrutura b√°sica de uma rede neural\n","\n","Um **perceptron** √© uma estrutura na forma $y = g(\\omega_0 + \\omega_1 x)$ que mapeia uma vari√°vel resposta $y$ √† uma vari√°vel preditora $x$ (*feature*) atrav√©s de uma fun√ß√£o de ativa√ß√£o $g(\\cdot)$. O perceptron √© o similar ao neur√¥nio em uma rede neural.\n","\n","Uma rede neural, no entanto, pode ser definida como uma *rede* de *perceptrons*:\n","\n","* Se $\\boldsymbol{x}$ √© um vetor $\\boldsymbol{x} = \\{ x_1, x_2, \\ldots, x_m \\}$ e $g_e(\\cdot)$ √© uma fun√ß√£o $\\mathbb{R}^m \\to \\mathbb{R}^n$ ent√£o os *perceptrons* $y_j = g_e \\left(\\omega_{j 0} + \\sum_i \\omega_{j i} x_i \\right)$, $j = 1, 2, \\ldots, n$, mapeiam $\\{ x_1, x_2, \\ldots, x_m \\} \\to \\{ y_1, y_2, \\ldots, y_n \\}$.\n","\n","* Se $\\boldsymbol{y}$ √© um vetor $\\boldsymbol{y} = \\{ y_1, y_2, \\ldots, y_n \\}$ e $h(\\cdot)$ √© uma fun√ß√£o $\\mathbb{R}^n \\to \\mathbb{R}^p$ ent√£o os *perceptrons* $v_k = h \\left(\\tau_{k 0} + \\sum_j \\tau_{k j} y_j \\right)$, $k = 1, 2, \\ldots, p$, mapeiam $\\{ y_1, y_2, \\ldots, y_n \\} \\to \\{ v_1, v_2, \\ldots, v_p \\}$.\n","\n","* Se $\\boldsymbol{v}$ √© um vetor $\\boldsymbol{v} = \\{ v_1, v_2, \\ldots, v_p \\}$ e $g_s(\\cdot)$ √© uma fun√ß√£o $\\mathbb{R}^p \\to \\mathbb{R}^q$ ent√£o os *perceptrons* $z_l = g_s \\left(\\phi_{l 0} + \\sum_k \\omega_{l k} v_k \\right)$, $l = 1, 2, \\ldots, q$, mapeiam $\\{ v_1, v_2, \\ldots, v_p \\} \\to \\{ z_1, z_2, \\ldots, z_q \\}$.\n","\n","* A *rede neural* pode ter quantas camadas quanto forem necess√°rias.\n","\n","* Uma camada que liga todas as entradas com todas as sa√≠das √© chamada de uma *camada densa*.\n","\n","* As camadas intermedi√°rias (como a que mapeia $\\mathbb{y} \\to \\mathbb{v}$ s√£o chamadas *camadas ocultas* ou *hidden layers*."]},{"cell_type":"markdown","metadata":{"id":"15l4VTh3pAfc"},"source":["## Defini√ß√£o do modelo de regress√£o linear simples"]},{"cell_type":"markdown","metadata":{"id":"wwJGmDrQ0EoB"},"source":["O modelo de regress√£o linear simples, definido por $y = \\beta_0 + \\beta_1 x$, pode ser definido como uma rede neural com uma √∫nica camada (√∫nico **perceptron**).\n","\n","O comando abaixo define uma rede neural **densa** de 1 perceptron (`units= 1`) cuja entrada √© uma lista de 1 posi√ß√£o (`input_shape= [1]`)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQFAr_xo0M4T"},"outputs":[],"source":["model = tf.keras.Sequential([\n","    keras.layers.Input(shape=(1,)),\n","    keras.layers.Dense(units=1)\n","  ])"]},{"cell_type":"markdown","metadata":{"id":"KhjZjZ-c0Ok9"},"source":["Fornecidos os vetores `y` e `x` o modelo ao ser treinado estimar√° os pesos $\\omega_0$ e $\\omega_1$ usando um **otimizador** e uma **fun√ß√£o de perda**.\n","\n","Neste exemplo, ser√£o utilizados o *otimizador* **Stochastic Gradient Descend** e a fun√ß√£o de perda ser√° aquela que minimiza a **m√©dia dos erros quadr√°ticos**.\n","\n","O otimizador **Stochastic Gradient Descend** √© semelhante ao algoritmo de Newton-Raphson; ser√° utilizado para minimizar a fun√ß√£o de perda."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m8YQN1H41L-Y"},"outputs":[],"source":["model.compile(optimizer='sgd', loss='mean_squared_error')"]},{"cell_type":"markdown","metadata":{"id":"ZqbyMtkPpHzs"},"source":["### Fornecendo os dados"]},{"cell_type":"markdown","metadata":{"id":"5QyOUhFw1OUX"},"source":["Para o modelo de exemplo, considere os vetores abaixo que mostram a convers√£o de temperaturas entre graus Celcius (vetor `xs`) para graus Fahrenheit (vetor `ys`). Os dados s√£o compostos de 6 valores inteiros descritos nos 2 vetores abaixo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Dxk4q-jzEy4"},"outputs":[],"source":["xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n","ys = np.array([-2.0, 1.0, 4.0, 7.0, 10.0, 13.0], dtype=float)"]},{"cell_type":"markdown","metadata":{"id":"dRHdvIw7pNvr"},"source":["### Treinando a Rede Neural"]},{"cell_type":"markdown","metadata":{"id":"n_YcWRElnM_b"},"source":["O treinamento da rede neural consiste simplesmente no \"ajuste\" do modelo. Ao chamar o m√©todo `model.fit()` os pesos $\\omega_0$ e $\\omega_1$ ser√£o ajustados atrav√©s do otimizador de modo que a fun√ß√£o de perda seja minimizada. √â um processo iterativo, no qual a cada passo o modelo √© \"refinado\". A quantidade de passos no ajuste √© dado por `epochs`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpRrl7WK10Pq"},"outputs":[],"source":["model.fit(xs, ys, epochs=500)"]},{"cell_type":"markdown","metadata":{"id":"kaFIr71H2OZ-"},"source":["Ap√≥s ajustar o modelo, este pode ser utilizado para se fazer previs√µes. O modelo em quest√£o √© dado por $y = 1 + 3 x$. O valor predito para $x = 10$ deve ser $y = 31$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oxNzL4lS2Gui"},"outputs":[],"source":["print(model.predict(np.array([10.0])))"]},{"cell_type":"markdown","metadata":{"id":"bABPSexJpa4q"},"source":["## Aplica√ß√£o: Vis√£o computacional"]},{"cell_type":"markdown","metadata":{"id":"qnyTxjK_GbOD"},"source":["A refer√™ncia para este tutorial est√° no **v√≠deo:** https://www.youtube.com/watch?v=j-35y1M9rRU&list=PLOU2XLYxmsII9mzQ-Xxug4l2o04JBrkLV&index=2"]},{"cell_type":"markdown","metadata":{"id":"yFLSlT3fj4Aj"},"source":["Os problemas chamados de **vis√£o computacional** consistem na capacidade do computador avaliar imagens para identificar padr√µes, identificar objetos, etc.\n","\n","Este exemplo usa uma base de dados implementada na biblioteca `tensorflow` que consiste em 70 mil imagens de vestu√°rio classificadas em 10 classes. O objetivo √© usar parte destas imagens para treinar o algoritmo a identificar os objetos e, posteriormente, utilizar o algoritmo para classificar os objetos n√£o utilizados no treinamento."]},{"cell_type":"markdown","metadata":{"id":"H4EGplkmpfEM"},"source":["### Descri√ß√£o do exemplo"]},{"cell_type":"markdown","metadata":{"id":"H41FYgtlHPjW"},"source":["O primeiro passo consiste em carregar a biblioteca TensorFlow."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q3KzJyjv3rnA"},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"2sKswgmaMenc"},"source":["A rede neural ser√° treinada para reconhecer itens de vestu√°rio de um conjunto de dados chamado *Fashion MNIST*. Mais detalhes sobre este conjunto de dados podem ser obtidos [aqui](https://github.com/zalandoresearch/fashion-mnist).\n","\n","Ele cont√©m 70.000 itens de vestimenta em 10 categorias diferentes. Cada item √© uma imagem 28x28 monocrom√°tica. Um exemplo dos itens pode ser visto aqui:\n","\n","![alt text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"]},{"cell_type":"markdown","metadata":{"id":"n_n1U5do3u_F"},"source":["O conjunto de dados `Fashion MNIST` est√° dispon√≠vel em `tf.keras.datasets`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PmxkHFpt31bM"},"outputs":[],"source":["mnist = tf.keras.datasets.fashion_mnist"]},{"cell_type":"markdown","metadata":{"id":"GuoLQQBT4E-_"},"source":["Ao invocar `load_data()` neste objeto ser√£o obtidos 2 conjuntos com 2 listas: 2 listas de treinamento e 2 listas de teste."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTdRgExe4TRB"},"outputs":[],"source":["(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"]},{"cell_type":"markdown","metadata":{"id":"jeof_U8Lpk4E"},"source":["### Qual a apar√™ncia destes dados?"]},{"cell_type":"markdown","metadata":{"id":"rw395ROx4f5Q"},"source":["Cada um dos itens √© uma matriz 28 x 28 com os valores de cada pixel que comp√µe a respectiva imagem."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2uet1TtmVws"},"outputs":[],"source":["print(training_images[0])"]},{"cell_type":"markdown","metadata":{"id":"jbB4bJW0LhiU"},"source":["Esta matriz pode ser visualizada como imagem:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPc9d3gJ3jWF"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.imshow(training_images[0]);"]},{"cell_type":"markdown","metadata":{"id":"rxi2-_uYmaHa"},"source":["Cada imagem possui um *label* composto por um n√∫mero de `0` a `9` que identifica o tipo de vestimenta. Este problema √©, portanto, um modelo de **aprendizado de m√°quina supervisionado** pois cada imagem j√° est√° previamente classificada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZuQxOnn7mksS"},"outputs":[],"source":["print(training_labels[0])"]},{"cell_type":"markdown","metadata":{"id":"3cbrdH225_nH"},"source":["Observe que cada imagem √© uma matriz de valores inteiros de `0` a `255` indicando uma escala monocrom√°tica para cada pixel. Para simplificar o modelo este valor ser√° convertido para um n√∫mero de ponto flutuante entre `0` e `1`. Este processo se chama '**normaliza√ß√£o**':"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kRH19pWs6ZDn"},"outputs":[],"source":["training_images  = training_images / 255.0\n","test_images = test_images / 255.0"]},{"cell_type":"markdown","metadata":{"id":"3DkO0As46lRn"},"source":["O modelo √© composto por uma rede neural com 3 \"camadas\" definidas em `tf.keras.models.Sequential()`.\n","\n","* A primeira camada **converte as matrizes 28 x 28** em um vetor com $28 \\times 28 = 784$ posi√ß√µes. Isto √© feito com o m√©todo `tf.keras.layers.Flatten()`.\n","* A segunda camada recebe o vetor proveniente da camada anterior e aplica a transforma√ß√£o $\\boldsymbol{z} = g_1(\\omega_{0} + \\omega_{1} \\cdot x_{1} + \\omega_{2} \\cdot x_{2} + \\cdots + \\omega_{784} \\cdot x_{784})$ resultando em um vetor de 128 respostas. A fun√ß√£o $g_1(\\cdot)$ √© chamada de **relU** e √© definida como $g_1(z) = \\max (0; z)$.\n","* A terceira camada recebe o vetor proveniente da chamada anterior e aplica a transforma√ß√£o $\\boldsymbol{y} = g_2(\\tau_0 + \\tau_1 \\cdot z_1 + \\tau_2 \\cdot z_2 + \\cdots + \\tau_{128} \\cdot z_{128})$ resultando em um vetor de 10 posi√ß√µes. A fun√ß√£o $g_2(\\cdot)$ √© chamda de **soft-max** e retorna um vetor com 10 posi√ß√µes em que aquela na qual $\\boldsymbol{y}$ √© m√°ximo assume o valor `1` e as demais o valor `0`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7mAyndG3kVlK"},"outputs":[],"source":["model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"]},{"cell_type":"markdown","metadata":{"id":"-lUcWaiX7MFj"},"source":["O modelo ser√° ajustado usando o otimizador *Adam* e a fun√ß√£o de perda `sparse_categorical_crossentropy`.\n","\n","O otimizador *Adam* √© um m√©todo do tipo *stochastic gradient descent* basedo na estima√ß√£o adaptativa dos momentos de primeira (m√©dia) e segunda ordem (vari√¢ncia).\n","\n","A fun√ß√£o de perda *sparse categorical cross-entropy* minimiza a entropia com base na probabilidade de cada categoria e a classifica√ß√£o correta para cada item."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BLMdl9aP8nQ0"},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(training_images, training_labels, epochs=5)"]},{"cell_type":"markdown","metadata":{"id":"-JJMsvSB-1UY"},"source":["A acur√°cia aumenta conforme os passos do modelo s√£o ajustados. O valor final √© algo em torno de 90% com apenas 5 passos.\n","\n","√â poss√≠vel verificar a acur√°cia do modelo para os dados n√£o utilizados no treinamento do modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WzlqsEzX9s5P"},"outputs":[],"source":["model.evaluate(test_images, test_labels)"]},{"cell_type":"markdown","metadata":{"id":"htldZNWcIPSN"},"source":["## Explorando o modelo"]},{"cell_type":"markdown","metadata":{"id":"rquQqIx4AaGR"},"source":["O comando abaixo calcula as probabilidades de classifica√ß√£o entre as 10 categorias para cada imagem de teste."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RyEIki0z_hAD"},"outputs":[],"source":["classifications = model.predict(test_images)\n","\n","print(classifications[0])\n","print(np.sum(classifications[0]))"]},{"cell_type":"markdown","metadata":{"id":"MdzqbQhRArzm"},"source":["O algoritmo n√£o classificou corretamente este objeto. Como se pode ver o objeto √© um cal√ßado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnBGOrMiA1n5"},"outputs":[],"source":["print(test_labels[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pGB7CrVcyVfK"},"outputs":[],"source":["plt.imshow(test_images[0])"]},{"cell_type":"markdown","metadata":{"id":"OgQSIfDSOWv6"},"source":["O c√≥digo abaixo explora o resultado obtido ao aumentar o n√∫mero de perceptrons na camada intermedi√°ria de 128 para 1024.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GSZSwV5UObQP"},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = 'adam',\n","              loss = 'sparse_categorical_crossentropy')\n","\n","model.fit(training_images, training_labels, epochs=5)\n","\n","model.evaluate(test_images, test_labels)\n","\n","classifications = model.predict(test_images)\n","\n","print(classifications[0])\n","print(test_labels[0])"]},{"cell_type":"markdown","metadata":{"id":"Dw1YgpKQ1-HC"},"source":["Tanto a entrada quanto a sa√≠da do modelo precisa ter as dimens√µes corretas dos objetos de entrada e os *labels*. Os dois exemplos abaixo demonstram isto."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExNxCwhcQ18S"},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","# Esta vers√£o tem a camada 'flatten' removida. Substitua o c√≥digo acima para ver um erro.\n","#model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n","#                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","\n","model.compile(optimizer = 'adam',\n","              loss = 'sparse_categorical_crossentropy')\n","\n","model.fit(training_images, training_labels, epochs=5)\n","\n","model.evaluate(test_images, test_labels)\n","\n","classifications = model.predict(test_images)\n","\n","print(classifications[0])\n","print(test_labels[0])"]},{"cell_type":"markdown","metadata":{"id":"ki46rRzvMkhd"},"source":["Mais um exemplo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMckVntcSPvo"},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","# Substitua a defini√ß√£o do modelo acima por este para uma rede com uma camada de sa√≠da com 5 n√≠veis\n","# e ter√° como resultado um erro!\n","# model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","#                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n","#                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = 'adam',\n","              loss = 'sparse_categorical_crossentropy')\n","\n","model.fit(training_images, training_labels, epochs=5)\n","\n","model.evaluate(test_images, test_labels)\n","\n","classifications = model.predict(test_images)\n","\n","print(classifications[0])\n","print(f\"A classe de maior probabilidade √© {np.argmax(classifications[0])}\" \\\n","       f\" e deveria ser {test_labels[0]}.\\n\")"]},{"cell_type":"markdown","metadata":{"id":"-0lF5MuvSuZF"},"source":["√â poss√≠vel aumentar a quantidade de *layers*. Neste exemplo n√£o faz muita diferen√ßa uma vez que os dados s√£o simples. Em imagens mais complexas se faz necess√°rio aumentar a quantidade de camadas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b1YPa6UhS8Es"},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = 'adam',\n","              loss = 'sparse_categorical_crossentropy')\n","\n","model.fit(training_images, training_labels, epochs=5)\n","\n","model.evaluate(test_images, test_labels)\n","\n","classifications = model.predict(test_images)\n","\n","print(classifications[0])\n","print(f\"A classe de maior probabilidade √© {np.argmax(classifications[0])}\" \\\n","       f\" e deveria ser {test_labels[0]}.\\n\")"]},{"cell_type":"markdown","metadata":{"id":"Bql9fyaNUSFy"},"source":["Aumentar a quantidade de passos na estima√ß√£o pode melhorar o ajuste, por√©m aumentar demasiadamente este valor causa um *overfitting* (o modelo fica viciado aos dados)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uE3esj9BURQe"},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = 'adam',\n","              loss = 'sparse_categorical_crossentropy')\n","\n","model.fit(training_images, training_labels, epochs=30)\n","\n","model.evaluate(test_images, test_labels)\n","\n","classifications = model.predict(test_images)\n","\n","print(classifications[34])\n","print(f\"A classe de maior probabilidade √© {np.argmax(classifications[34])}\" \\\n","       f\" e deveria ser {test_labels[34]}.\\n\")"]},{"cell_type":"markdown","metadata":{"id":"B9pfX2rnyVj8"},"source":["### Qual o efeito da normaliza√ß√£o?"]},{"cell_type":"markdown","metadata":{"id":"HS3vVkOgCDGZ"},"source":["Os modelos de redes neurais podem ganhar acur√°cia se os valores de entrada forem normalizados para um intervalo com menor escala (em geral o intervalo `0` a `1`). O c√≥digo abaixo demonstra isso."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDqNAqrpCNg0"},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)\n","mnist = tf.keras.datasets.fashion_mnist\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","# Experimente remover a normaliza√ß√£o, comentando as 2 linhas seguintes.\n","training_images=training_images/255.0\n","test_images=test_images/255.0\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","])\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n","model.fit(training_images, training_labels, epochs=5)\n","model.evaluate(test_images, test_labels)\n","classifications = model.predict(test_images)\n","print(classifications[0])\n","print(f\"A classe de maior probabilidade √© {np.argmax(classifications[0])}\" \\\n","       f\" e deveria ser {test_labels[0]}.\\n\")"]},{"cell_type":"markdown","metadata":{"id":"E7W2PT66ZBHQ"},"source":["A rede pode ser treinada at√© atingir um determinado n√≠vel de acur√°cia. Isto √© feito com a defini√ß√£o de uma class **call-back** como demonstrado abaixo. Este recurso pode inibir o *overfitting* do modelo, uma vez que o ajuste √© interrompido antes do modelo *viciar* com os dados de treinamento."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pkaEHHgqZbYv"},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('accuracy')>0.9):\n","      print(\"\\nReached 90% accuracy so cancelling training!\")\n","      self.model.stop_training = True\n","\n","callbacks = myCallback()\n","mnist = tf.keras.datasets.fashion_mnist\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","training_images=training_images/255.0\n","test_images=test_images/255.0\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","])\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lWOJW2O0yp3l"},"source":["## Convolu√ß√£o"]},{"cell_type":"markdown","metadata":{"id":"uMkOz2r4jYN0"},"source":["Este tutorial √© baseado no **v√≠deo:** https://www.youtube.com/watch?v=PCgLmzkRM38&list=PLOU2XLYxmsII9mzQ-Xxug4l2o04JBrkLV&index=3\n","\n","As *convolu√ß√µes* junto com o *Pooling* s√£o usados para comprimir e simplificar as imagens enfatizando suas caracter√≠sticas."]},{"cell_type":"markdown","metadata":{"id":"0XqsQnEEysj8"},"source":["### Limita√ß√µes do modelo DNN (*deep neural network*) anterior"]},{"cell_type":"markdown","metadata":{"id":"CzjEQ8O6j3ti"},"source":["No modelo anterior as imagens do conjunto de dados do MNIST eram imagens 28 x 28, monocrom√°ticas e com os objetos centralizados. Exemplos destas imagens eram\n","![Imagem de um sweater e uma bota](https://cdn-images-1.medium.com/max/1600/1*FekMt6abfFFAFzhQcnjxZg.png)\n","\n","O DNN anterior aprendeu a distinguir em alguns pixeis um sweater de uma bota, mas como o modelo classificaria esta imagem?\n","\n","![image of boots](https://cdn.pixabay.com/photo/2013/09/12/19/57/boots-181744_1280.jpg)\n","\n","Para avaliar imagens mais complexas torna-se necess√°rio usar *convolu√ß√µes* para filtrar elementos da imagem e extrair caracter√≠sticas.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"O6jE6KrQlCld"},"source":["Inicialmente, carregue as bibliotecas necess√°rias."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ad3876eylKqK"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import scipy\n","i = scipy.datasets.ascent()"]},{"cell_type":"markdown","metadata":{"id":"9nr8X_Jilly1"},"source":["A imagem que ser√° utilizada para o tutorial √© a seguinte:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8zvJwrDwlte2"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.grid(False)\n","plt.gray()\n","plt.axis('off')\n","plt.imshow(i)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"L6K4eKj8lz_E"},"source":["√â a imagem de uma escadaria. Existem diversos atributos nesta imagem, sobretudo linhas horizontais e verticais. A convolu√ß√£o permite ressaltar estes elementos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p0z8e7p8mDxb"},"outputs":[],"source":["i_transformed = np.copy(i)\n","size_x = i_transformed.shape[0]\n","size_y = i_transformed.shape[1]"]},{"cell_type":"markdown","metadata":{"id":"JAtql-SXmPxz"},"source":["√â poss√≠vel definir um filtro como uma matrix 3 por 3."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BUgda5V1mWG8"},"outputs":[],"source":["# This filter detects edges nicely\n","# It creates a convolution that only passes through sharp edges and straight\n","# lines.\n","\n","#Experiment with different values for fun effects.\n","#filter = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]]\n","\n","# A couple more filters to try for fun!\n","filter = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n","#filter = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n","\n","# If all the digits in the filter don't add up to 0 or 1, you\n","# should probably do a weight to get it to do so\n","# so, for example, if your weights are 1,1,1 1,2,1 1,1,1\n","# They add up to 10, so you would set a weight of .1 if you want to normalize them\n","weight  = 1"]},{"cell_type":"markdown","metadata":{"id":"vtA6eQoUmaVT"},"source":["Agora define-se a convolu√ß√£o; mantendo uma margem de 1 pixel, multiplique cada vizinho do pixel pela possi√ß√£o correspondente no filtro. Depois multiplica-se pelo peso e mant√©m-se o valor entre `0` e `255`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iaynPKN2m5nb"},"outputs":[],"source":["for x in range(1,size_x-1):\n","  for y in range(1,size_y-1):\n","      convolution = 0.0\n","      convolution = convolution + (i[x - 1, y-1] * filter[0][0])\n","      convolution = convolution + (i[x, y-1] * filter[0][1])\n","      convolution = convolution + (i[x + 1, y-1] * filter[0][2])\n","      convolution = convolution + (i[x-1, y] * filter[1][0])\n","      convolution = convolution + (i[x, y] * filter[1][1])\n","      convolution = convolution + (i[x+1, y] * filter[1][2])\n","      convolution = convolution + (i[x-1, y+1] * filter[2][0])\n","      convolution = convolution + (i[x, y+1] * filter[2][1])\n","      convolution = convolution + (i[x+1, y+1] * filter[2][2])\n","      convolution = convolution * weight\n","      if(convolution<0):\n","        convolution=0\n","      if(convolution>255):\n","        convolution=255\n","      i_transformed[x, y] = convolution"]},{"cell_type":"markdown","metadata":{"id":"Yaqjml_km7gq"},"source":["A imagem transformada √© a seguinte:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t39K6pv3m9kr"},"outputs":[],"source":["# Plot the image. Note the size of the axes -- they are 512 by 512\n","plt.gray()\n","plt.grid(False)\n","plt.imshow(i_transformed)\n","#plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"cFb41K_sy8Jk"},"source":["## Pooling"]},{"cell_type":"markdown","metadata":{"id":"58yFVHRPnMCU"},"source":["Existem diferentes formas de *pooling*; em particular ser√° aplicada o *max-pooling*.\n","\n"," A idea √© iterar sobre a imagem e, para cada pixel, tomar os valores √† direita, abaixo e diagonal √† direita. Tomando o maior valor entre estes resultando em uma imagem 1/4 menor que a original. As caracter√≠sticas da imagem se mant√©m apesar da compress√£o.\n","\n","O c√≥digo mostra um *pooling* (2, 2) resultando em uma imagem 1/4 do tamanho original."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H_R1wXRMn_MT"},"outputs":[],"source":["new_x = int(size_x/2)\n","new_y = int(size_y/2)\n","newImage = np.zeros((new_x, new_y))\n","for x in range(0, size_x, 2):\n","  for y in range(0, size_y, 2):\n","    pixels = []\n","    pixels.append(i_transformed[x, y])\n","    pixels.append(i_transformed[x+1, y])\n","    pixels.append(i_transformed[x, y+1])\n","    pixels.append(i_transformed[x+1, y+1])\n","    pixels.sort(reverse=True)\n","    newImage[int(x/2),int(y/2)] = pixels[0]\n","\n","# Plot the image. Note the size of the axes -- now 256 pixels instead of 512\n","plt.gray()\n","plt.grid(False)\n","plt.imshow(newImage)\n","#plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"bXTvsICen9UL"},"source":["Esta t√©cnica √© utilizada para simplificar imagens em modelos mais complexos."]},{"cell_type":"markdown","metadata":{"id":"cVeG_pxQzFMs"},"source":["## Melhorando a acur√°cia da vis√£o computacional com convolu√ß√µes"]},{"cell_type":"markdown","metadata":{"id":"P3cFaxGPqs0J"},"source":["Nos exemplos anteriores as imagens de vestimentas foram reconhecidas usando uma *Deep Neural Network* (DNN) com tr√™s camadas -- a camada de entrada (com o formato dos dados), a camada de sa√≠da (com o formato desejado para a sa√≠da) e uma camada ocultar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5AuMCIG4rxLM"},"outputs":[],"source":["import tensorflow as tf\n","mnist = tf.keras.datasets.fashion_mnist\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","training_images=training_images / 255.0\n","test_images=test_images / 255.0\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","])\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(training_images, training_labels, epochs=5)\n","\n","test_loss = model.evaluate(test_images, test_labels)"]},{"cell_type":"markdown","metadata":{"id":"BH-MZWzvr5hM"},"source":["A acur√°cia √© algo em torno de 89% no treinamento e 87% na valida√ß√£o. √â poss√≠vel melhorar usando *convolu√ß√µes*. Trata-se de algo bastante similar com o processamento de imagens por filtros (como este: https://en.wikipedia.org/wiki/Kernel_(image_processing)).\n","\n","O c√≥digo abaixo √© a mesma rede neural que antes, mas com camadas de convolu√ß√£o adicionadas. √â mais demorado para ajustar, mas a acur√°via deve ser maior:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ti89ERN7sqbk"},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)\n","mnist = tf.keras.datasets.fashion_mnist\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","training_images=training_images.reshape(60000, 28, 28, 1)\n","training_images=training_images / 255.0\n","test_images = test_images.reshape(10000, 28, 28, 1)\n","test_images=test_images/255.0\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Input(shape=(28,28,1)),\n","  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","  tf.keras.layers.MaxPooling2D(2, 2),\n","  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","  tf.keras.layers.MaxPooling2D(2, 2),\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(128, activation='relu'),\n","  tf.keras.layers.Dense(10, activation='softmax')\n","])\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","model.fit(training_images, training_labels, epochs=5)\n","test_loss = model.evaluate(test_images, test_labels)\n"]},{"cell_type":"markdown","metadata":{"id":"Bshypszjs7-1"},"source":["A precis√£o deve estar em torno de 93% nos dados de treinamento e 91% nos dados de valida√ß√£o.\n","\n","Observe o c√≥digo novamente, e veja, passo a passo como a convolu√ß√£o √© constru√≠da:\n","\n","O **primeiro passo** √© a obten√ß√£o dos dados. H√° uma pequena mudan√ßa no formato dos dados de entrada. A convolu√ß√£o espera um √∫nico *tensor* (matriz multidimensional) contendo todos os dados, ao inv√©s de 60 mil itens 28 x 28 x 1 em uma lista, √© fornecida uma matriz que 4 dimens√µes 60.000 x 28 x 28 x 1 e o mesmo √© feito para as imagens de teste.\n","\n","```\n","import tensorflow as tf\n","mnist = tf.keras.datasets.fashion_mnist\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","training_images=training_images.reshape(60000, 28, 28, 1)\n","training_images=training_images / 255.0\n","test_images = test_images.reshape(10000, 28, 28, 1)\n","test_images=test_images/255.0\n","```\n","\n","O **pr√≥ximo passo** √© definir o modelo. Ao inv√©s de uma camada de entrada no topo, adiciona-se uma convolu√ß√£o. Os par√¢metros s√£o:\n","\n","1. O n√∫mero de convolu√ß√µes para gerar. Totalmente arbitr√°rio, mas uma boa estrat√©gia √© usar um m√∫ltiplo de 32.\n","2. O tamanho da convolu√ß√£o, neste caso uma matriz 3 x 3.\n","3. A fun√ß√£o de ativa√ß√£o para usar.\n","4. O formato dos dados de entrada.\n","\n","A convolu√ß√£o √© seguida de uma camada *MaxPooling* usada para comprimir os dados, reduzindo a imagem em 25%.\n","\n","Chamando `model.summary()` √© poss√≠vel ver o tamanho do modelo e observar que as camadas *MaxPooling* reduzem a dimens√£o para 1/4.\n","\n","```\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n","  tf.keras.layers.MaxPooling2D(2, 2),\n","```\n","\n","Uma segunda convolu√ß√£o\n","\n","```\n","  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","  tf.keras.layers.MaxPooling2D(2, 2),\n","```\n","\n","Seguido de uma camada *Flatten* para transformar a imagem em um vetor.\n","\n","```\n","  tf.keras.layers.Flatten(),\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dNqR_af9zaQN"},"source":["## Visualizando as convolu√ß√µes e o pooling"]},{"cell_type":"markdown","metadata":{"id":"TzA-ldVovhCi"},"source":["Este c√≥digo mostra as convolu√ß√µes em gr√°ficos. A vari√°vel (test_labels[;100]) cont√©m os labels das 100 imagens iniciais do conjunto de teste.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTkLqZZ3v7di"},"outputs":[],"source":["print(test_labels[:100])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K60av5_mv-k5"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import tensorflow as tk\n","from keras import models\n","\n","f, axarr = plt.subplots(3,4)\n","FIRST_IMAGE=0\n","SECOND_IMAGE=7\n","THIRD_IMAGE=26\n","CONVOLUTION_NUMBER=1\n","\n","layer_outputs= [layer.output for layer in model.layers]\n","activation_model= models.Model(inputs= model.inputs, outputs= layer_outputs)\n","\n","for x in range(4):\n","  f1= activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n","  axarr[0,x].imshow(f1[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n","  axarr[0,x].grid(False)\n","\n","  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n","  axarr[1,x].imshow(f2[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n","  axarr[1,x].grid(False)\n","\n","  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n","  axarr[2,x].imshow(f3[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n","  axarr[2,x].grid(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejDBu34JwV_B"},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)\n","mnist = tf.keras.datasets.mnist\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","training_images=training_images.reshape(60000, 28, 28, 1)\n","training_images=training_images / 255.0\n","test_images = test_images.reshape(10000, 28, 28, 1)\n","test_images=test_images/255.0\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Input(shape=(28,28,1)),\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(10, activation='softmax')\n","])\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(training_images, training_labels, epochs=10)\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(test_acc)"]},{"cell_type":"markdown","metadata":{"id":"iCnqUT8AzrJM"},"source":["# Convolu√ß√µes com imagens complexas"]},{"cell_type":"markdown","metadata":{"id":"Y0yRTXVJ7tto"},"source":["**Refer√™ncia:** https://www.youtube.com/watch?v=0kYIZE8Gl90&list=PLOU2XLYxmsII9mzQ-Xxug4l2o04JBrkLV&index=5&t=838s\n","\n","Exemplo de classifica√ß√£o entre humanos e cavalos. Obtendo os dados:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7I4QkDL8YCg"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","\n","train_image, train_label = tfds.as_numpy(tfds.load(\n","    'horses_or_humans',\n","    split= 'train',\n","    batch_size= -1,\n","    as_supervised= True\n","))\n","\n","print(type(train_image), train_image.shape)\n","print(train_label)\n","\n","test_image, test_label = tfds.as_numpy(tfds.load(\n","    'horses_or_humans',\n","    split= 'test',\n","    batch_size= -1,\n","    as_supervised= True\n","))\n","\n","print(type(test_image), test_image.shape)\n","print(test_label)\n"]},{"cell_type":"markdown","metadata":{"id":"YmsfFLxT_sfJ"},"source":["Construindo o modelo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C89mKU_K_uYI"},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H_d3CYwfO-Qv"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","# Parameters for our graph; we'll output images in a 4x4 configuration\n","nrows = 4\n","ncols = 4\n","\n","# Index for iterating over images\n","pic_index = 0\n","\n","# Set up matplotlib fig, and size it to fit 4x4 pics\n","fig = plt.gcf()\n","fig.set_size_inches(ncols * 4, nrows * 4)\n","\n","pic_index += 8\n","\n","\n","\n","#for i, img_path in enumerate(next_horse_pix+next_human_pix):\n","#  # Set up subplot; subplot indices start at 1\n","#  sp = plt.subplot(nrows, ncols, i + 1)\n","#  sp.axis('Off') # Don't show axes (or gridlines)\n","#\n","#  img = mpimg.imread(img_path)\n","#  plt.imshow(img)\n","#\n","#plt.show()\n","\n","for i in range(16):\n","  sp = plt.subplot(nrows, ncols, i + 1)\n","  sp.axis('Off')\n","  plt.imshow(train_image[i])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"d998kK0OAHQp"},"source":["Adiciona-se camadas de *convolu√ß√£o* e uma camada *flatten* ao resultado final para alimentar as camadas densamente conectadas.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ojsD6CPQAO95"},"outputs":[],"source":["model = tf.keras.models.Sequential([\n","    tk.keras.layers.Input(shape=(300,300,3)),\n","    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"4KIO4S6bQ_77"},"source":["A coluna \"output shape\" mostra o tamanho das caracter√≠sticas em cada camada sucessiva. As camadas de convolu√ß√£o reduz o tamanho dos mapas de caracter√≠sticas devido ao deslocamento e a cada camada de *pooling* diminui a dimens√£o.\n","\n","O modelo ser√° treinado usando a fun√ß√£o de perda `binary_crossentropy`, pois √© um problema de classifica√ß√£o bin√°ria e a ativa√ß√£o final √© uma sigm√≥ide. (Para relembrar as m√©tricas de fun√ß√µes de perda, veja [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/descending-into-ml/video-lecture).) Ser√° utilizado o otimizador `rmsprop` com uma taxa de aprendizagem de `0.001`. Durante o treinamento ser√° monitorada a acur√°cia da classifica√ß√£o.\n","\n","**NOTA**: Neste caso, usando o [algoritmo de otimiza√ß√£o RMSprop](https://wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp) √© prefer√≠vel ao [gradiente estoc√°stico descendente](https://developers.google.com/machine-learning/glossary/#SGD) (SGD), pois o RMSprop automatiza a taxa de aprendizagem. (Outros otimizadores, tais como o [Adam](https://wikipedia.org/wiki/Stochastic_gradient_descent#Adam) e o [Adagrad](https://developers.google.com/machine-learning/glossary/#AdaGrad), tamb√©m adapta autom√°ticamente a taxa de aprendizagem durante o treinamento.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RUvJSAzkSz5T"},"outputs":[],"source":["import tensorflow as tk\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=tk.keras.optimizers.RMSprop(learning_rate= 0.001),\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"msROosxsVEvs"},"source":["### Treinando o modelo\n","\n","O modelo ser√° treinado em 15 *epochs*. A perda (*loss*) e a acur√°cia (*accuracy*) s√£o grandes indicadores do progresso do treinamento. O modelo prediz a classifica√ß√£o dos dados e, comparando √†s classes reais, calcula os resultados."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-C6_fHuVii3"},"outputs":[],"source":["history = model.fit(\n","      train_image, train_label,\n","      validation_data = (test_image, test_label),\n","      epochs=1,\n","      steps_per_epoch=8,\n","      validation_steps=8,\n","      verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"0JzW-0ghbn8z"},"source":["## Executando o modelo\n","\n","Ap√≥s ajustar os modelos √© poss√≠vel observar que a rede categoriza as imagens com diversos erros apesar da acur√°cia no treinamento ser superior a 99%.\n","\n","Isto ocorre por algo chamado **overfitting**, que significa que a rede neural √© treinada com um conjunto de dados muito limitados -- existem apenas 500 imagens de cada classe. Assim o modelo se torna excelente para reconhecer as imagens do conjunto de treinamento mas falha ao avaliar imagens fora do conjunto.\n","\n","Quanto mais dados s√£o usados no treinamento, melhor o modelo se torna. No entanto, existem dive\n","rsas t√©cnicas que podem ser usadas para melhorar o treinamento do modelo, apesar dos dados limitados, incluindo algo chamado de *Image Augmentation*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1vlxwqWIdNh0"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","classes = model.predict(test_image, batch_size= 10)\n","\n","# Parameters for our graph; we'll output images in a 4x4 configuration\n","nrows = 16\n","ncols = 16\n","\n","# Index for iterating over images\n","pic_index = 0\n","\n","# Set up matplotlib fig, and size it to fit 4x4 pics\n","fig = plt.gcf()\n","fig.set_size_inches(ncols * 2, nrows * 2)\n","\n","pic_index += 8\n","\n","for i in range(test_image.shape[0]):\n","  sp = plt.subplot(nrows, ncols, i + 1)\n","  sp.axis('Off')\n","  sp.title.set_text(\"Humano\" if classes[i] > 0.5 else \"Cavalo\")\n","  plt.imshow(test_image[i])\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"16s1fBbth5_J"},"source":["## Visualizando representa√ß√µes intermediarias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o0nnAhU0iKym"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tk\n","import random\n","\n","from keras import models\n","\n","images = np.concatenate((train_image, test_image), axis = 0)\n","\n","# Let's define a new Model that will take an image as input, and will output\n","# intermediate representations for all layers in the previous model after\n","# the first.\n","successive_outputs = [layer.output for layer in model.layers[1:]]\n","#visualization_model = Model(img_input, successive_outputs)\n","visualization_model = models.Model(inputs = model.inputs, outputs = successive_outputs)\n","# Let's prepare a random input image from the training set.\n","#horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n","#human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n","#img_path = random.choice(horse_img_files + human_img_files)\n","\n","img = random.choice(range(images.shape[0]))\n","\n","#img = load_img(img_path, target_size=(300, 300))  # this is a PIL image\n","x = images[img]  # Numpy array with shape (150, 150, 3)\n","x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n","\n","print(np.any(x > 255))\n","\n","# Rescale by 1/255\n","x = x / 255.0\n","\n","# Let's run our image through our network, thus obtaining all\n","# intermediate representations for this image.\n","successive_feature_maps = visualization_model.predict(x)\n","\n","# These are the names of the layers, so can have them as part of our plot\n","layer_names = [layer.name for layer in model.layers]\n","\n","# Now let's display our representations\n","for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n","  if len(feature_map.shape) == 4:\n","    # Just do this for the conv / maxpool layers, not the fully-connected layers\n","    n_features = feature_map.shape[-1]  # number of features in feature map\n","    # The feature map has shape (1, size, size, n_features)\n","    size = feature_map.shape[1]\n","    # We will tile our images in this matrix\n","    display_grid = np.zeros((size, size * n_features))\n","    for i in range(n_features):\n","      # Postprocess the feature to make it visually palatable\n","      x = feature_map[0, :, :, i]\n","      x -= x.mean()\n","      if np.any(x > 0):\n","        x /= x.std()\n","      x *= 64\n","      x += 128\n","      x = np.clip(x, 0, 255).astype('uint8')\n","      # We'll tile each filter into this big horizontal grid\n","      display_grid[:, i * size : (i + 1) * size] = x\n","    # Display the grid\n","    scale = 20. / n_features\n","    plt.figure(figsize=(scale * n_features, scale))\n","    plt.title(layer_name)\n","    plt.grid(False)\n","    plt.imshow(display_grid, aspect='auto', cmap='viridis')"]},{"cell_type":"markdown","metadata":{"id":"0Av2lnGGlTtM"},"source":["Como se pode ver as imagens se tornam cada vez mais abstratas e compactas. As representa√ß√µes sinalizam as caracter√≠sticas que a rede identifica e mostram cada vez menos caracter√≠sticas sendo \"ativadas\"; muitas s√£o ajustadas em zero. Isto √© chamado de \"esparticidade.\" A esparticidade da representa√ß√£o √© a caracter√≠stica chave para o *deep learning*.\n","\n","Estas representa√ß√µes carregam cada vez menos informa√ß√µes sobre os pixeis originais da imagem, e cada vez mais informa√ß√µes refinadas sobre a classe da imagem. √â poss√≠vel pensar em uma `convnet` (ou uma rede neural em particular) como uma destilaria de informa√ß√µes.\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/lmoroney/mlday-tokyo/blob/master/Lab1-Hello-ML-World.ipynb","timestamp":1689271706429}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}