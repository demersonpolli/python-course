{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPQduXHAnLoHIapIiPia7ff"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Scikit-learn"],"metadata":{"id":"bqYgRZoAZZ2p"}},{"cell_type":"markdown","source":["A biblioteca **scikit-learn** é uma biblioteca que disponibiliza uma gama de modelos estatísticos especializados para o uso em *aprendizado de máquina*.\n","\n","Nesta aula não será tratado o aprendizado de máquina propriamente dito, mas serão demonstrados a sintaxe do **scikit-learn** e algumas aplicações básicas em modelagem estatística."],"metadata":{"id":"1m_jH05jD7Cv"}},{"cell_type":"markdown","source":["## Regressão linear"],"metadata":{"id":"YUvY8bkKZgu3"}},{"cell_type":"markdown","source":["Os modelos de regressão linear permite identificar uma relação linear entre variáveis explicativas e uma variável resposta.\n","\n","O modelo é formulado da seguinte forma\n","\n","$$\n","\\min_{\\omega} (X \\beta - y)^2 + \\alpha \\beta^w\n","$$\n","\n","em que $X$ é a matriz de covariáveis, $y$ é o vetor de respostas, $\\beta$ é o vetor de coeficientes e $\\alpha \\geq 0$ é o parâmetro de penalização do coeficiente (quanto maior o valor $\\alpha$ mais robusto à colinearidade é o modelo). Tomando $\\alpha = 0$ obtém-se o modelo de regressão linear usual.\n","\n","O código abaixo demonstra o uso da função `sklearn.linear_model()` para ajuste de modelos de regressão e a comparação entre as regressões Ridge e linear no ajuste de um modelo degenerado."],"metadata":{"id":"OrTGuyXOGccy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yfoznNDOD5Ab"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn import linear_model\n","\n","X_train = np.c_[0.5, 1].T\n","y_train = [0.5, 1]\n","X_test = np.c_[0, 2].T\n","\n","np.random.seed(0)\n","\n","classifiers = dict(\n","    ols=linear_model.LinearRegression(), ridge=linear_model.Ridge(alpha=0.1)\n",")\n","\n","for name, clf in classifiers.items():\n","    fig, ax = plt.subplots(figsize=(4, 3))\n","\n","    for _ in range(6):\n","        this_X = 0.1 * np.random.normal(size=(2, 1)) + X_train\n","        clf.fit(this_X, y_train)\n","\n","        ax.plot(X_test, clf.predict(X_test), color=\"gray\")\n","        ax.scatter(this_X, y_train, s=3, c=\"gray\", marker=\"o\", zorder=10)\n","\n","    clf.fit(X_train, y_train)\n","    ax.plot(X_test, clf.predict(X_test), linewidth=2, color=\"blue\")\n","    ax.scatter(X_train, y_train, s=30, c=\"red\", marker=\"+\", zorder=10)\n","\n","    ax.set_title(name)\n","    ax.set_xlim(0, 2)\n","    ax.set_ylim((0, 1.6))\n","    ax.set_xlabel(\"X\")\n","    ax.set_ylabel(\"y\")\n","\n","    fig.tight_layout()\n","\n","plt.show()"]},{"cell_type":"code","source":["# Dados sobre automóveis\n","df = pd.DataFrame(\n","    { \"mpg\": [21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4,\n","              22.8, 19.2, 17.8, 16.4, 17.3, 15.2, 10.4, 10.4,\n","              14.7, 32.4, 30.4, 33.9, 21.5, 15.5, 15.2, 13.3,\n","              19.2, 27.3, 26.0, 30.4, 15.8, 19.7, 15.0, 21.4],\n","      \"cyl\": [6, 6, 4, 6, 8, 6, 8, 4,\n","               4, 6, 6, 8, 8, 8, 8, 8,\n","               8, 4, 4, 4, 4, 8, 8, 8,\n","               8, 4, 4, 4, 8, 6, 8, 4],\n","      \"disp\": [160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7,\n","               140.8, 167.6, 167.6, 275.8, 275.8, 275.8, 472.0, 460.0,\n","               440.0,  78.7,  75.7,  71.1, 120.1, 318.0, 304.0, 350.0,\n","               400.0,  79.0, 120.3,  95.1, 351.0, 145.0, 301.0, 121.0],\n","      \"hp\": [110, 110,  93, 110, 175, 105, 245,  62,\n","              95, 123, 123, 180, 180, 180, 205, 460,\n","             440,  66,  52,  65,  97, 150, 150, 245,\n","             175,  66,  91, 113, 264, 175, 335, 109],\n","      \"drat\": [3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69,\n","               3.92, 3.92, 3.92, 3.07, 3.07, 3.07, 2.93, 3.00,\n","               3.23, 4.08, 4.93, 4.22, 3.70, 2.76, 3.15, 3.73,\n","               3.08, 4.08, 4.43, 3.77, 4.22, 3.62, 3.54, 4.11],\n","      \"wt\": [2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190,\n","             3.150, 3.440, 3.440, 4.070, 3.730, 3.780, 5.250, 5.424,\n","             5.345, 2.200, 1.615, 1.835, 2.465, 3.520, 3.435, 3.840,\n","             3.845, 1.935, 2.140, 1.513, 3.170, 2.770, 3.570, 2.780],\n","      \"qsec\": [16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00,\n","               22.90, 18.30, 18.90, 17.40, 17.60, 18.00, 17.98, 17.82,\n","               17.42, 19.47, 18.52, 19.90, 20.01, 16.87, 17.30, 15.41,\n","               17.05, 18.90, 16.70, 16.90, 14.50, 15.50, 14.60, 18.60],\n","      \"vs\": [0, 0, 1, 1, 0, 1, 0, 1,\n","             1, 1, 1, 0, 0, 0, 0, 0,\n","             0, 1, 1, 1, 1, 0, 0, 0,\n","             0, 1, 0, 1, 0, 0, 0, 1],\n","      \"am\": [1, 1, 1, 0, 0, 0, 0, 0,\n","             0, 0, 0, 0, 0, 0, 0, 0,\n","             0, 1, 1, 1, 0, 0, 0, 0,\n","             0, 1, 1, 1, 1, 1, 1, 1],\n","      \"gear\": [4, 4, 4, 3, 3, 3, 3, 4,\n","               4, 4, 4, 3, 3, 3, 3, 3,\n","               3, 4, 4, 4, 3, 3, 3, 3,\n","               3, 4, 5, 5, 5, 5, 5, 4],\n","      \"carb\": [4, 4, 1, 1, 2, 1, 4, 2,\n","               2, 4, 4, 3, 3, 3, 4, 4,\n","               4, 1, 2, 1, 1, 2, 2, 4,\n","               2, 1, 2, 2, 4, 6, 8, 2]\n","    },\n","    index= [\"Mazda RX4\", \"Mazda RX4 Wag\", \"Datsun 710\", \"Hornet 4 Drive\",\n","            \"Hornet Sportabout\", \"Valiant\", \"Duster 360\", \"Merc 240D\",\n","            \"Merc 230\", \"Merc 280\", \"Merc 280C\", \"Merc 450SE\",\n","            \"Merc 450SL\", \"Merc 450SLC\", \"Cadillac Fleetwood\", \"Lincoln Continental\",\n","            \"Chrysler Imperial\", \"Fiat 128\", \"Honda Civic\", \"Toyota Corolla\",\n","            \"Toyota Corona\", \"Dodge Challenger\", \"AMC Javelin\", \"Camaro Z28\",\n","            \"Pontiac Firebird\", \"Fiat X1-9\", \"Porsche 914-2\", \"Lotus Europa\",\n","            \"Ford Pantera L\", \"Ferrari Dino\", \"Maserati Bora\", \"Volvo 142E\"])"],"metadata":{"id":"8BB6gqelI_zy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn import linear_model\n","\n","X = df.loc[:, [\"hp\"]].to_numpy()\n","y = df.loc[:, [\"mpg\"]].to_numpy()\n","\n","np.random.seed(0)\n","\n","ols = linear_model.LinearRegression()\n","ridge = linear_model.Ridge(alpha=0.1)\n","\n","Xt = pd.DataFrame(np.array(range(50, 455, 5)))\n","\n","ols.fit(X, y)\n","fig, ax = plt.subplots(figsize=(4, 3))\n","\n","\n","ax.plot(Xt, ols.predict(Xt), color=\"gray\")\n","ax.scatter(X, y, s = 3, c= \"blue\", marker= \"o\")\n","ax.set_title(\"Regressão linear\")\n","ax.set_xlabel(\"Potência (HP)\")\n","ax.set_ylabel(\"Consumo (milha/gal.)\")\n","\n","plt.show()\n","\n","\n","ridge.fit(X, y)\n","fig, ax = plt.subplots(figsize=(4, 3))\n","\n","\n","ax.plot(Xt, ridge.predict(Xt), color=\"gray\")\n","ax.scatter(X, y, s = 3, c= \"blue\", marker= \"o\")\n","ax.set_title(\"Regressão Ridge\")\n","ax.set_xlabel(\"Potência (HP)\")\n","ax.set_ylabel(\"Consumo (milha/gal.)\")\n","\n","plt.show()\n"],"metadata":{"id":"AuAGTAY4pCxW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Classificação de objetos"],"metadata":{"id":"d_rbWMWDakaF"}},{"cell_type":"markdown","source":["Os modelos de regressão podem, por exemplo, serem utilizados para fazer a classificação de objetos. Abaixo há um exemplo do uso da *regressão Ridge* para classificar documentos de blogs com relação à sua origem. Uma adaptação deste modelo permite, por exemplo, implementar algoritmos de análise de sentimento para textos diversos (basta trocar a indicação de origem por variáveis indicadoras de sentimentos nos textos de treinamento para calibrar o modelo)."],"metadata":{"id":"3M_Ew294-5pJ"}},{"cell_type":"code","source":["from time import time\n","\n","from sklearn.datasets import fetch_20newsgroups\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","categories = [\n","    \"alt.atheism\",\n","    \"talk.religion.misc\",\n","    \"comp.graphics\",\n","    \"sci.space\",\n","]\n","\n","\n","def size_mb(docs):\n","    return sum(len(s.encode(\"utf-8\")) for s in docs) / 1e6\n","\n","\n","def load_dataset(verbose=False, remove=()):\n","    \"\"\"Load and vectorize the 20 newsgroups dataset.\"\"\"\n","\n","    data_train = fetch_20newsgroups(\n","        subset=\"train\",\n","        categories=categories,\n","        shuffle=True,\n","        random_state=42,\n","        remove=remove,\n","    )\n","\n","    data_test = fetch_20newsgroups(\n","        subset=\"test\",\n","        categories=categories,\n","        shuffle=True,\n","        random_state=42,\n","        remove=remove,\n","    )\n","\n","    # order of labels in `target_names` can be different from `categories`\n","    target_names = data_train.target_names\n","\n","    # split target in a training set and a test set\n","    y_train, y_test = data_train.target, data_test.target\n","\n","    # Extracting features from the training data using a sparse vectorizer\n","    t0 = time()\n","    vectorizer = TfidfVectorizer(\n","        sublinear_tf=True, max_df=0.5, min_df=5, stop_words=\"english\"\n","    )\n","    X_train = vectorizer.fit_transform(data_train.data)\n","    duration_train = time() - t0\n","\n","    # Extracting features from the test data using the same vectorizer\n","    t0 = time()\n","    X_test = vectorizer.transform(data_test.data)\n","    duration_test = time() - t0\n","\n","    feature_names = vectorizer.get_feature_names_out()\n","\n","    if verbose:\n","        # compute size of loaded data\n","        data_train_size_mb = size_mb(data_train.data)\n","        data_test_size_mb = size_mb(data_test.data)\n","\n","        print(\n","            f\"{len(data_train.data)} documentos - \"\n","            f\"{data_train_size_mb:.2f}MB (conjunto de treinamento)\"\n","        )\n","        print(f\"{len(data_test.data)} documentos - {data_test_size_mb:.2f}MB (conjunto de teste)\")\n","        print(f\"{len(target_names)} categorias\")\n","        print(\n","            f\"vetorização do conjunto de treinamento concluído em {duration_train:.3f}s \"\n","            f\"a {data_train_size_mb / duration_train:.3f}MB/s\"\n","        )\n","        print(f\"amostras: {X_train.shape[0]}, características: {X_train.shape[1]}\")\n","        print(\n","            f\"vetorização do conjunto de teste concluído em {duration_test:.3f}s \"\n","            f\"at {data_test_size_mb / duration_test:.3f}MB/s\"\n","        )\n","        print(f\"amostras: {X_test.shape[0]}, características: {X_test.shape[1]}\")\n","\n","    return X_train, X_test, y_train, y_test, feature_names, target_names"],"metadata":{"id":"Lf2PT-ycx0x3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Usando a função definida acima é possível carregar os textos dos grupos de discussão."],"metadata":{"id":"9Sui_Vk9zse_"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test, feature_names, target_names = load_dataset(\n","    verbose=True\n",")"],"metadata":{"id":"sg05ze52yH9P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Os textos são classificados utilizando uma regressão Ridge."],"metadata":{"id":"C7Vb5KMJzyt2"}},{"cell_type":"code","source":["from sklearn.linear_model import RidgeClassifier\n","\n","clf = RidgeClassifier(tol=1e-2, solver=\"sparse_cg\")\n","clf.fit(X_train, y_train)\n","pred = clf.predict(X_test)"],"metadata":{"id":"9vhNBzuvyN83"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["O resultado é uma matriz de confundimento, na qual se mostra a quantidade de textos classificados pelo algoritmo (com relação à origem) em comparação com a origem real."],"metadata":{"id":"LBcoUFubz5Gm"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","fig, ax = plt.subplots(figsize=(10, 5))\n","ConfusionMatrixDisplay.from_predictions(y_test, pred, ax=ax)\n","ax.xaxis.set_ticklabels(target_names)\n","ax.yaxis.set_ticklabels(target_names)\n","_ = ax.set_title(\n","    f\"Matriz de confundimento para {clf.__class__.__name__}\\nsobre os documentos originais\"\n",")"],"metadata":{"id":"bqBpAtwlyQYw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cada palavra do texto (característica) possui um efeito associado à classificação em cada uma das listas de discussão."],"metadata":{"id":"K_jFi0e40DbH"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","\n","def plot_feature_effects():\n","    # learned coefficients weighted by frequency of appearance\n","    average_feature_effects = clf.coef_ * np.asarray(X_train.mean(axis=0)).ravel()\n","\n","    for i, label in enumerate(target_names):\n","        top5 = np.argsort(average_feature_effects[i])[-5:][::-1]\n","        if i == 0:\n","            top = pd.DataFrame(feature_names[top5], columns=[label])\n","            top_indices = top5\n","        else:\n","            top[label] = feature_names[top5]\n","            top_indices = np.concatenate((top_indices, top5), axis=None)\n","    top_indices = np.unique(top_indices)\n","    predictive_words = feature_names[top_indices]\n","\n","    # plot feature effects\n","    bar_size = 0.25\n","    padding = 0.75\n","    y_locs = np.arange(len(top_indices)) * (4 * bar_size + padding)\n","\n","    fig, ax = plt.subplots(figsize=(10, 8))\n","    for i, label in enumerate(target_names):\n","        ax.barh(\n","            y_locs + (i - 2) * bar_size,\n","            average_feature_effects[i, top_indices],\n","            height=bar_size,\n","            label=label,\n","        )\n","    ax.set(\n","        yticks=y_locs,\n","        yticklabels=predictive_words,\n","        ylim=[\n","            0 - 4 * bar_size,\n","            len(top_indices) * (4 * bar_size + padding) - 4 * bar_size,\n","        ],\n","    )\n","    ax.legend(loc=\"lower right\")\n","\n","    print(\"top 5 keywords per class:\")\n","    print(top)\n","\n","    return ax\n","\n","\n","_ = plot_feature_effects().set_title(\"Efeito médio das características sobre os dados originais\")"],"metadata":{"id":"fPBrOCsI0DsH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Agrupamento de objetos"],"metadata":{"id":"wUCZYRSubHpw"}},{"cell_type":"markdown","source":["Além de regressão e classificação de objetos, a biblioteca *scikit* permite realizar o agrupamento de objetos. O exemplo abaixo mostra o agrupamento de imagens de dígitos escritos à mão. O objetivo é identificar se apenas as diferenças na grafia destes dígitos permitiriam identificar de forma satisfatória cada dígito de acordo com diferentes métodos de agrupamento hierárquico."],"metadata":{"id":"16luktDa0-Jv"}},{"cell_type":"code","source":["# Authors: Gael Varoquaux\n","# License: BSD 3 clause (C) INRIA 2014\n","\n","from time import time\n","\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","from sklearn import datasets, manifold\n","\n","digits = datasets.load_digits()\n","X, y = digits.data, digits.target\n","n_samples, n_features = X.shape\n","\n","np.random.seed(0)\n","\n","\n","# ----------------------------------------------------------------------\n","# Visualize the clustering\n","def plot_clustering(X_red, labels, title=None):\n","    x_min, x_max = np.min(X_red, axis=0), np.max(X_red, axis=0)\n","    X_red = (X_red - x_min) / (x_max - x_min)\n","\n","    plt.figure(figsize=(6, 4))\n","    for digit in digits.target_names:\n","        plt.scatter(\n","            *X_red[y == digit].T,\n","            marker=f\"${digit}$\",\n","            s=50,\n","            c=plt.cm.nipy_spectral(labels[y == digit] / 10),\n","            alpha=0.5,\n","        )\n","\n","    plt.xticks([])\n","    plt.yticks([])\n","    if title is not None:\n","        plt.title(title, size=17)\n","    plt.axis(\"off\")\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","\n","\n","# ----------------------------------------------------------------------\n","# 2D embedding of the digits dataset\n","print(\"Computing embedding\")\n","X_red = manifold.SpectralEmbedding(n_components=2).fit_transform(X)\n","print(\"Done.\")\n","\n","from sklearn.cluster import AgglomerativeClustering\n","\n","for linkage in (\"ward\", \"average\", \"complete\", \"single\"):\n","    clustering = AgglomerativeClustering(linkage=linkage, n_clusters=10)\n","    t0 = time()\n","    clustering.fit(X_red)\n","    print(\"%s :\\t%.2fs\" % (linkage, time() - t0))\n","\n","    plot_clustering(X_red, clustering.labels_, \"%s linkage\" % linkage)\n","\n","\n","plt.show()"],"metadata":{"id":"ApwpmDpn0-uf"},"execution_count":null,"outputs":[]}]}